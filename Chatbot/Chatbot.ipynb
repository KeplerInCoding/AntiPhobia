{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569b9373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\chatbot\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n",
      "2023-11-30 03:00:39 - \u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://192.168.1.31:8080\n",
      "2023-11-30 03:00:39 - \u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "2023-11-30 03:01:09 - 127.0.0.1 - - [30/Nov/2023 03:01:09] \"GET / HTTP/1.1\" 200 -\n",
      "2023-11-30 03:01:10 - 127.0.0.1 - - [30/Nov/2023 03:01:10] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "2023-11-30 03:02:56 - 192.168.1.31 - - [30/Nov/2023 03:02:56] \"GET / HTTP/1.1\" 200 -\n",
      "2023-11-30 03:02:56 - 192.168.1.31 - - [30/Nov/2023 03:02:56] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import chainlit as cl\n",
    "from langchain import HuggingFaceHub, PromptTemplate, LLMChain\n",
    "from getpass import getpass\n",
    "\n",
    "HUGGINGFACEHUB_API_TOKEN = getpass()\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = HUGGINGFACEHUB_API_TOKEN\n",
    "\n",
    "model_id = \"openchat/openchat_3.5\"\n",
    "conv_model = HuggingFaceHub(huggingfacehub_api_token=os.environ['HUGGINGFACEHUB_API_TOKEN'],\n",
    "                            repo_id=model_id,\n",
    "                            model_kwargs={\"temperature\": 0.8, \"max_new_tokens\": 150})\n",
    "\n",
    "template = \"\"\"You are a helpful AI assistant providing support to someone dealing with phobias. Your goal is to offer friendly and informative advice on overcoming fears. \n",
    "\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "@cl.on_chat_start\n",
    "def main():\n",
    "    prompt = PromptTemplate(template=template, input_variables=['query'])\n",
    "    conv_chain = LLMChain(llm=conv_model, prompt=prompt, verbose=True)\n",
    "    cl.user_session.set(\"llm_chain\", conv_chain)\n",
    "\n",
    "@cl.on_message\n",
    "async def process_message(message: str):\n",
    "    llm_chain = cl.user_session.get(\"llm_chain\")\n",
    "    res = await llm_chain.acall(message, callbacks=[cl.AsyncLangchainCallbackHandler()])\n",
    "\n",
    "    # Perform post-processing on the received response here\n",
    "    # 'res' is a dictionary, and the response text is stored under the key \"text\"\n",
    "    return res[\"text\"]\n",
    "\n",
    "# If you are using Flask\n",
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return \"Server is running.\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=8080)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0678352",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Chatbot.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d66d7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
